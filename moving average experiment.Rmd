---
title: "Moving Average Experiment"
output: html_notebook
---

```{r loading packages and installing any missing, echo = FALSE}
l.packages <- c('plyr','dplyr','ggplot2','TTR','shiny','data.table','RColorBrewer')
for (package in l.packages) {
    if (!require(package, character.only=T, quietly=T, warn.conflicts=F)) {
        install.packages(package, repos="http://cran.us.r-project.org")
        suppressPackageStartupMessages(library(package, quietly=T, character.only=T))
    }
}
```

```{r loading/preparing the data, echo = FALSE}
# loading data sets
df.pace.limits <- readRDS('datasets/df.pace.climits.rds')
l.pace <- readRDS('datasets/ldf.pace.rds')
df.nba_teams <- readRDS('datasets/df.nba_teams.rds')

# splitting by season
l.pace.split <- lapply(l.pace, function(x){split(x, f = x$season)})

# combining back into data.frame
ldf.pace.split <- lapply(l.pace.split, function(x) lapply(x, function(y) as.data.frame(y)))
```

## Introduction/Background

I love statistics. I don't mean numbers, although I suppose that's wrapped up in it. I mean [Statistics](https://en.wikipedia.org/wiki/Statistics) as in, the branch of mathematics. There's one specific application of statistics that I love above all the rest -- forecasting. It's the most interesting application as well as the most difficult. Anyone can forecast today with little more than the click of a button using the extensive data analysis tools out there today, but to do so with the highest degree of accuracy requires a great deal of mathematical knowledge generally, and statistics knowledge specifically.

I'm also a big sports fanatic. There's a lot to love: spectacle, drama, intensity, strategy, camaraderie, and more. I left one of my favorite parts out though -- statistics. This time, I *do* mean statistics as in numbers. Sports provide an interminable, ever-changing flow of statistics with which there are potentially infinite analyses to be derived.

So I painted the big picture, now let me bring things back to the very small corner this little analysis will cover. I would like to be able to forecast NBA games with the highest degree of accuracy I can. NBA statistics are legion and there are relationships between the different statistics which greatly complicate this forecasting process. There is one stat though that applies across most of the others, and that is **Pace**, which is used to determine per-possession stats. Per-possession stats will give much greater accuracy to forecasting models over per-game stats. If you aren't already familiar with this idea, the reasoning is actually fairly simple. Per-game statistics are heavily biased by overtime, and also vary quite a bit depending on how 'fast' or 'slow' each particular game is (e.g. 'fast' against teams like the Warriors or Rockets who play at a quick pace, 'slow' against teams like the Jazz who play at a slow pace). Because of this variance in Pace,  per-game statistics aren't as meaningful since they aren't all based on a smaller common unit. Pace is based on number of possessions, which is scalable across over all games, all teams, and all years. This makes Pace and per-possession statistics the most unbiased^[*bias* (and therefore *unbiased*) is an important statistical term and has multiple applications and meanings. A statistic being biased doesn't necessarily make it always worse than an unbiased statistic. In this case however, it almost definitely would. https://en.wikipedia.org/wiki/Bias_of_an_estimator] statistics we can use, which will improve forecasting accuracy.

Now we can get to the meat of the analysis. My objective is to predict Pace in the most accurate way possible, to use as a foundation for the rest of the predictive statistics. But how to predict Pace? 

## Data Exploration

A good first step in any analysis is visualizing the data you are hoping to analyze. To get a feel for what Pace might look like for a team across a single season, let's take a look at an example team's pace by game from last season (2016-2017). The Utah Jazz are the default team, but you can look at any other team's pace from last season by choosing them from the dropdown menu.

```{r shiny team pace time series, echo = FALSE}
shinyAppDir("paceTS"
)
```


Hmm... patterns look familiar? How about now?

![Caption for the picture.](pictures/apple stock.png)


Looks kind of like a stock price chart right? We can use the similarities to our advantage and use a concept well-known to the stock price forecasting world -- moving averages.

Moving averages are a critical component to financial forecasts. The reason why this is that things like stock price (and in our case, Pace) are *auto-correlated*, meaning that each stock price (or Pace) at time *n* is very closely related to the stock price right before it, at time *n-1*. There can also be yearly and/or seasonal adjustments you can include in these type of models as well (e.g. larger sales during the holidays). This family of methods/analysis is called [Time Series Analysis](https://onlinecourses.science.psu.edu/stat510/node/47) and can get much more complicated. I'm going to keep it simple and only focus on moving averages for this analysis.

One quick check I wanted to make before moving on was whether Pace differs significantly in Home games vs Away games. Initially I thought this would be a significant difference. As it turns out, the differences are trivial. They are well within the statistically significant confidence bounds (and in the overwhelming majority of cases, it's not even close), which you can see for each team below.


```{r shiny team pace confidence limits, echo = FALSE}
shinyAppDir("PaceCL"
)
```

## Moving Averages

Now that we have established that Home/Away isn't an important distinction to make, we can move on to the real meat of this analysis. I wanted to analyze whether some sort of moving average would be better for predicting Pace than a simple season-long average. A simple season-long average is what you would see reported as 'Pace' on sites like [Basketball Reference](https://www.basketball-reference.com/leagues/NBA_2017.html#misc_stats::none).^[It's also important at this point to point out that Pace is calculated by a formula which you can see here: https://www.basketball-reference.com/about/glossary.html] If you go to that link, this table shows the ending average 2017 Regular Season Pace for each team. Throughout the season however, this table (and Pace specifically) will be updated daily. So after each team has played their first game, the Pace column will show the pace for that game only, since it would be the only game of the season so far. After 2 games, it would be the average of those 2, etc. until we get to 82 games at which point it will be the average of all 82. So after any given number of games, all games contribute the same weight to the season-long average. Fairly simple right? Here's the potential problem I see with this: when viewed *cummulatively* across an entire season, it gives an exponentially skewed weighting to earlier games. If I lost you there, take a look at the following plot, which shows the total cummulative weight each game would contribute to a season-long average Pace. 

```{r cummulative weights calculation, echo = FALSE}
df.wts <- data.table(Game = numeric(), Weight = numeric(), Cumm.Weight = numeric())[1:82]
df.wts$Game <- seq_len(82)
df.wts$Weight <- 1/seq_len(82)
for(i in 1:82){
  df.wts$Cumm.Weight[i] <- sum(df.wts$Weight[i:82])
}
```

```{r cummulative weights graph, echo = FALSE}
g <- ggplot(data = df.wts, aes(x = Game, y = Cumm.Weight))
h <- g + geom_point(aes(x = Game, y = Cumm.Weight))
i <- h + theme_dark()
j <- i + ggtitle('Total Weight Contributed to Season-Long Average Pace') + theme(plot.title = element_text(hjust = 0.5, face = 'bold', size = 16)) + labs(y = 'Cummulative Weight')
j
```

For example, after the 1st game, the weight of the 1st game will be equal to 1. After the 2nd: 1/2, ... , 10th: 1/10, ... , 40th: 1/40 ... , 82nd: 1/82. The 82nd game at this point will also have this same weight of 1/82. Summing all of these weights across the whole season gives a total weight of 4.99 for the 1st game but a total weight of just .0122 for the 82nd game. To return to the stock price analogy, this would be like resetting your price average on January 1st of every year and ignoring all the data you have collected from previous years. You could get lucky and it may work out to your benefit, but this does not seem like the best way to approach a moving average to me, which is why I thought I could come up with something better, more akin to a stock-price-esque moving average.

There are many different types of moving averages (also sometimes referred to as rolling or running averages), but I'm going to focus on just the two most basic and most common ones you might see: Simple Moving Average (or SMA) and Exponential Moving Average (or EMA). There's one commonality between the two types and one difference.

The commonality between both moving averages is that the average looks at a rolling 'window' of time. The window can be any length you want. For our example, it would be any *n* number of games immediately preceding the game we are hoping to predict. If the window we choose is 5 games, then only the last 5 games would count in our average. So for Game 6, Games 1 thru 5 would be the basis of the average. For Game 82, Games 77 thru 81 would be the basis. Each moving average also assigns a weight to each game.

The difference between the averages is the weight that is assigned to each game inside that window. For simple moving averages, each game is weighted equally. So if our window is 5 games, then each game will contribute 1/5 or 20% to the average. For exponential moving averages, the weights decrease exponentially the further back we go. So the most recent games count for more in the average than the later games. The degree to which they decrease depends on what's called the "smoothing ratio". This smoothing ratios that can be chosen are anything between 0 and 1, therefore are effectively infinite. The most common ratio that is used is 2/(n+1), n being the length of the window we have chosen. So with the example window of 5 games, the exponential smoothing ratio would be 2/6 or 33%.^[You can see a better explanation of exponential moving averages calculations here: http://www.dummies.com/personal-finance/investing/stocks-trading/how-to-calculate-exponential-moving-average-in-trading/]


## Experimental Design

So how do we can we determine which moving average type and which window length is best? The approach I like to use in cases like this is an experimental one. Meaning: let's just try a bunch of different ones and see what happens! Luckily technology enables this with relative ease. I did the hard part of writing several functions in R to calculate the different moving averages with different lengths so that we can compare the results against each other.(insert footnote thing here linking to the code maybe?)

There are 3 statistics that we'll be judging the results by. These are **error**, **bias**, and **correlation**. In each case, these statistics are averages across all 30 teams. The fact that we are averaging across 30 teams introduces extra complexity to the analysis. This extra complexity matters, but does not ultimately change the outcome in this case, so to keep the analysis as simple as possible, I am going to ignore that extra complexity to keep the analysis simple.

```{r season-long MA function and calculation, echo = FALSE}
# function
f.seasonMA <- function(x, var, prev, newcol){
  x[newcol] <- numeric(nrow(x))
  x[newcol][1,] <- x[prev][1,]
  for(i in 2:nrow(x)){
    lag <- i-1
    suhm <- sum(x[var][1:lag,]) + x[prev][1,]
    meen <- suhm/i
    x[newcol][i,] <- meen
  }
  return(as.data.frame(x))
}

# calculation
l.pace.split <- lapply(l.pace.split, function(x) lapply(x, f.seasonMA,'Pace','prevpace','seasonMA'))

# re-combining season lists back together
l.pace <- lapply(l.pace.split, function(x) ldply(x))
```

```{r Moving Average functions, echo = FALSE}
# Simple Moving Average
f.SMA <- function(x, n, var, var2, newcol){
  newn <- n+1
  x[newcol] <- numeric(nrow(x))
  sma <- SMA(x[var], n)
  for(i in 1:n){
    x[newcol][i,] <- x[var2][i,]
  }
  for(i in newn:nrow(x)){
    lag <- i-1
    x[newcol][i,] <- sma[lag]
  }
  return(as.data.frame(x))
}

# Exponential Moving Average
f.EMA <- function(x, n, var, var2, newcol){
  newn <- n+1
  newn2 <- n
  x[newcol] <- numeric(nrow(x))
  x[newcol][1,] <- x[var2][1,]
  ema <- TTR::EMA(x[var], n=1,  ratio=2/(newn2+1))
  for(i in 2:nrow(x)){
    lag <- i-1
    x[newcol][i,] <- ema[lag]
  }
  return(as.data.frame(x))
}  
```

```{r Statistical Functions, echo = FALSE}
# Error

f.error.per <- function(x, var1, var2){
      SSE <- sum((x[var1] - x[var2])^2)
      n <- nrow(x)
      RMSE <- sqrt(SSE/n)
      return(RMSE)
}

f.error.rmse <- function(data, ma.var){
  sapply(data, function(x) mean(f.error.per(x, 'Pace', ma.var)))
}

# Correlation
f.cors <- function(data, ma.var, meth){
  cor(x = data['Pace'], y = data[ma.var], method = meth)
}
            

# Bias
f.bias.per <- function(x, var1, var2){
  b <- sum(x[var1] - x[var2])
  n <- nrow(x)
  ba <- b/n
  return(ba)
}

f.bias.mean.per <- function(data,ma.var){
  sapply(data, function(x) mean(f.bias.per(x, 'Pace', ma.var)))
}
```

```{r Calculation Function, echo = FALSE}
f.ma <- function(data, type, nz){
  # data: list of dataframes (each list item is a dataframe of a single team's data. list naming is e.g. 'nba-atl')
  #   e.g. pace.list.allmas
  # type: type of moving average fcn. e.g.
  #   e.g. 'SMA' or 'EMA'
  # nz: list/vector of 'n' values to use
  #   e.g. 5:15
  
  ## SETUP
  
    # necessary variables
      len <- length(nz)
      len1 <- 1 + len
      f.name <- paste0('f.',type)
      new.data <- data
      errors <- list()
      fn.types <- c(mean, sd, min, max)
      fn.var.names <- c('error','e.sd','e.min','e.max','e.spread','cor.p','cor.k','cor.s')
      fn.var.names.b <- c('bias','b.sd','b.min','b.max','b.spread')
      methods <- list('pearson','kendall','spearman')
    
    # getting variable names
    namez <- lapply(nz, function(x){paste0(type,x)})
    
    # calculating new columns
    for(i in 1:len){
      new.data <- lapply(new.data, f.name, nz[i],'Pace','seasonMA',namez[[i]])
    }
    
    # list of all MA variables
    ma.namez <- append('seasonMA',namez)
  
  
  ## ERROR
  
    # error data list calculation and renaming
    errors <- lapply(ma.namez, function(x) {f.error.rmse(new.data,x)})
    names(errors) <- ma.namez
    
    # descriptive stats
    stats <- lapply(fn.types, function(x){lapply(errors, x)})
    stats[[5]] <- mapply('-',stats[[4]],stats[[3]], SIMPLIFY = F)
  
  
  # CORR
  
    # correlations
    cors <- lapply(new.data, function(x) lapply(ma.namez, function(y) lapply(methods, function(z) f.cors(x, y, z))))
    
    # dumby list items
    stats[[6]] <- stats[[5]]
    stats[[7]] <- stats[[5]]
    stats[[8]] <- stats[[5]]
    
    # cor loop
    for(j in 1:len1){
      for(i in 6:8){
        i2 <- i-5
        stats[[i]][[j]] <- mean(sapply(cors, function(x) mean(x[[j]][[i2]])))
      }
    }
    
    # naming list
    names(stats) <- fn.var.names
  
  
  ## BIAS
  
    # bias data list calculation and renaming
    bias <- lapply(ma.namez, function(x){f.bias.mean.per(new.data,x)})
    names(bias) <- ma.namez
    
    # descriptive stats
    stats.b <- lapply(fn.types, function(x) lapply(bias, x))
    stats.b[[5]] <- mapply('-',stats.b[[4]],stats.b[[3]], SIMPLIFY = F)
    names(stats.b) <- fn.var.names.b
  
  
  ## AGGREGATING
  
    # combining into table
    stats.c <- append(stats, stats.b)
    
    stats.table <- rbindlist(stats.c, use.names = T)
    row.names(stats.table) <- names(stats.c)
    
    stats.table.t <- transpose(stats.table)
    colnames(stats.table.t) <- rownames(stats.table)
    rownames(stats.table.t) <- colnames(stats.table)
    
    # rank table
    colms <- colnames(stats.table.t)
    stats.table.r <- stats.table.t
    
    for(i in 1:13){
      stats.table.r[,i] <- frankv(stats.table.t, cols = i)
    }
      # reverse rank for cor columns
      stats.table.r[,6] <- frank(stats.table.t, -cor.p)
      stats.table.r[,7] <- frank(stats.table.t, -cor.k)
      stats.table.r[,8] <- frank(stats.table.t, -cor.s)
      
      # reverse rank for min.b
      stats.table.r[,11] <- frank(stats.table.t, -b.min)
      
      # need rank of absolute values for bias column
      stats.table.r[,9] <- frank(abs(stats.table.t), bias)
      
      #average rank
      stats.table.r$avg.rank <- rowMeans(stats.table.r,na.rm = T)
    
  ## RETURN
  stats.ret <- list(stats.table.t,stats.table.r)
  return(stats.ret)
}
```

Now let me briefly explain each of these 3 statistics we're using and why they are important.

1. Error
First, there are different applications of what 'error' could mean. The specific error term I'm using is called Root Mean Square Error or [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation). Essentially what the number actually means is how far off our predicted Pace is, on average. Error can be any number between 0 and infinity, but as you might expect, we want this statistic to be as small as possible.

2. Bias
What this represents is the average amount per game that the moving averages over or underestimate Pace on average across all 30 teams. While the Error represents the spread of the data, Bias represents how closely the predictions 'center' around the true Pace values. So what we really want is for this statistic to be as close to zero as possible. If it were literally zero, that would make our statistic an *unbiased* estimator. Having an unbiased estimator is a highly desirable trait in statistical analysis. It isn't always possible and in some cases a biased estimator will actually be a better predictor. At the very least though, we want to minimize the bias as much as possible, while also minimizing RMSE. 

3. Correlation
As with Error, there are different types of correlations that can be used. The statistic I will be using is actually an average of [3 different types of correlations](https://en.wikipedia.org/wiki/Correlation_and_dependence): Pearson (which is by far the most common, and what most people use), Kendall, and Spearman. And again, averaged across all 30 teams. Correlation can be any number between -1 and 1. In our case, we want our predicted Pace to be as close to the real value as possible, which would mean perfectly positively correlated and would have a correlation value of 1. So we want this statistic to be as large as possible.

A couple additional details I need to mention first before we take a look at the results.

1. The data I had available was for the last two seasons: 2015-2016 and 2016-2017. Keep in mind that this only covers the regular season, no playoffs or pre-season. 
2. The intial 'seed' (i.e. prediction for the very first game of the 2015-2016 season, since we have no game data prior to that) used for every type of moving average was each team's ending season average Pace for the 2014-2015 season, which I obtained from Basketball Reference. 
3. For 2016-2017 (and would be the case for any additional year that is added), the seed for the season-long average was again set to the previous season's average Pace. Take note that this is *only* for the season-long average. The moving averages do not need more than the single starting seed, since the moving averages *never* reset like the season-long average does.


Whew. OK, now we get to start the fun part -- let the experimenting begin! 

I chose to start with just a few window lengths to compare against the season-long average, to get a taste of what the different lengths will do for us: 
-regular season-long moving average. This is the 'control' group (i.e. what we are testing against)
-Simple Moving Averages of length 5, 10, and 20
-Exponential Moving Averages of length 5, 10, and 20

In financial models, it's quite common to see moving average lengths much longer than these I have chosen. However, in the context of an NBA season, I think around the last 20 games is the longest I would care to consider, and around the last 5 games is the shortest I would consider. The reasons for this are fairly simple -- you don't want to have too few games, otherwise your moving average can get easily skewed by outliers. And you don't want too many games or else your moving average won't be sensitive enough to changes teams have made, such as trades, injuries, etc. A balance between all of these considerations (not to mention the balance across all 30 teams and all years that we have data for) is what we are really looking to achieve here.



## The Results - Part I

Let's take a look at the results.

```{r Function calls and output simplification 5 10 20, echo = FALSE}
# lengths 5, 10, and 20
l.stats.sma.51020 <- f.ma(l.pace,'SMA',c(5,10,20))
l.stats.ema.51020 <- f.ma(l.pace,'EMA',c(5,10,20))
df.stats.51020 <- rbind(l.stats.sma.51020[[1]],l.stats.ema.51020[[1]][2:4,])
row.names(df.stats.51020) <- append(row.names(l.stats.sma.51020[[1]]),row.names(l.stats.ema.51020[[1]])[-1])
#   adding additional variables for simplification and plotting
        df.stats.51020$correlation <- rowMeans(df.stats.51020[,6:8])
        df.stats.51020$type <- as.factor(c('Season',rep_len('SMA',3),rep_len('EMA',3)))
        df.stats.51020$length <- c(4,5,10,20,5,10,20) # note: length '4' for season-long MA is only used for plotting
        
        df.stats.51020.simplified <- df.stats.51020[,c('error','bias','correlation')]
        row.names(df.stats.51020.simplified) <- append(row.names(l.stats.sma.51020[[1]]),row.names(l.stats.ema.51020[[1]])[-1])
```


```{r MA type and length comparison plots 5 10 15, fig.height=12,fig.width=6, echo = FALSE}
colrz.d <- c('azure','yellow','springgreen')

df.stats.51020.melt <- df.stats.51020[,c('error','bias','correlation','type','length')]
df.stats.51020.melt$bias <- abs(df.stats.51020.melt$bias)
df.stats.51020.melt <- melt.data.table(df.stats.51020.melt, id.vars = c('length','type'))

g <- ggplot(data = df.stats.51020.melt, aes(x = length, y = value, color = type))
h <- g + geom_point(aes(x = length, y = value))
i <- h + geom_line(aes(x = length, y = value))
j <- i + scale_color_manual(name = "MA type", values = colrz.d)
k <- j + theme_dark()
l <- k + ggtitle('Moving Average Type and Length Comparisons') + theme(plot.title = element_text(hjust = 0.5, face = 'bold', size = 16),axis.title.y = element_blank())
m <- l + facet_grid(variable~., scales = 'free_y')
m
```

A few things jump out to me from these graphs. Let me break it down by each of the three statistics.

1. Error
Unfortunately moving averages aren't reducing the overall error of prediction vs season-long average, though they aren't far off in some cases. We can see that the longer moving average window, the smaller the error gets. Season-long average has the smallest error by just a hair. It's also clear that error drops a large amount between window lengths 5 and 10. 

2. Bias
Moving averages look to have a clear advantage over season-long average here, especially for the shorter window lengths. In the reverse of what we see with Error, Bias looks to increase as the moving average length increases.

3. Correlation
Again, as with Bias, here we can see a large improvement from moving averages vs season-long average. Season-long average has by far the worst correlation. For both SMA and EMA, it's interesting to note that correlation peaks at window length 10. Additionally, the correlations for window length 20 are inferior to window length 5.

Overall, it looks like we have a kind of sweet spot around window length 10, where the error is greatly reduced, the correlation peaks, and the bias remains relatively small. Armed with that information, I went back and got the data for every window length between 5 and 15. I chose to go to 15 instead of 20 since we have already seen that length 20 is quite inferior to length 10, so going just to length 15 should be sufficient. Let's check the results of this extended experiment.



## The Results - Part II

```{r Function calls and output simplification 5 thru 15, echo = FALSE}
# lengths 5 thru 15
l.stats.sma.5thru15 <- f.ma(l.pace,'SMA',5:15)
l.stats.ema.5thru15 <- f.ma(l.pace,'EMA',5:15)
df.stats.5thru15 <- rbind(l.stats.sma.5thru15[[1]],l.stats.ema.5thru15[[1]][2:12,])
row.names(df.stats.5thru15) <- append(row.names(l.stats.sma.5thru15[[1]]),row.names(l.stats.ema.5thru15[[1]])[-1])
#   adding additional variables for simplification and plotting
        df.stats.5thru15$correlation <- rowMeans(df.stats.5thru15[,6:8])
        df.stats.5thru15$type <- as.factor(c('Season',rep_len('SMA',11),rep_len('EMA',11)))
        df.stats.5thru15$length <- c(4,5:15,5:15) # note: length '4' for season-long MA is only used for plotting
        
        df.stats.5thru15.simplified <- df.stats.5thru15[,c('error','bias','correlation')]
        row.names(df.stats.5thru15.simplified) <- append(row.names(l.stats.sma.5thru15[[1]]),row.names(l.stats.ema.5thru15[[1]])[-1])
```

```{r MA type and length comparison plots 5 thru 15, fig.height=12,fig.width=6, echo = FALSE}
colrz.d <- c('azure','yellow','springgreen')

df.stats.5thru15.melt <- df.stats.5thru15[,c('error','bias','correlation','type','length')]
df.stats.5thru15.melt$bias <- abs(df.stats.5thru15.melt$bias)
df.stats.5thru15.melt <- melt.data.table(df.stats.5thru15.melt, id.vars = c('length','type'))

g <- ggplot(data = df.stats.5thru15.melt, aes(x = length, y = value, color = type))
h <- g + geom_point(aes(x = length, y = value))
i <- h + geom_line(aes(x = length, y = value))
j <- i + scale_color_manual(name = "MA type", values = colrz.d)
k <- j + theme_dark()
l <- k + ggtitle('Error × Moving Average Type and Length') + theme(plot.title = element_text(hjust = 0.5, face = 'bold', size = 16),axis.title.y = element_blank())
m <- l + facet_grid(variable~., scales = 'free_y')
m
```

So now how do we know which moving average is best, given this information we've gathered? This part is where I would say the *art* of Statistics comes in. In big data applications, you often can/should leave questions like this up to the machine to decide what models and/or parameters are best using statistical tests. This is not the case with our data, and to be frank, I'm not aware of a test that could be used in this particular situation anyway (although I don't doubt there could be one or several). Since we're dealing with a relatively small dataset and we've already done the legwork in obtaining good summary statistics with which to base our choice off of, I think we can decide based on just the graphs you see above. 

Let's take a brief look at each of the graphs. First, the Error curves for both SMA and EMA look nearly identical. The Bias curve for SMA looks much more appealing than the EMA curve/line does. For that reason, at this point I almost certainly am going to choose an SMA over any EMA, unless the Correlation of the EMAs blow the SMAs out of the water. Well, they don't. Similar to Error, the Correlation curves for both SMA and EMA look quite similar. The much smoother overall EMA Correlation curve has a certain appeal that they SMA Correlation curve does not, but overall they aren't too different.

So... which one? I'll tell you the one I would choose. I would choose the SMA with window length 9. But why? Let me start with the most obvious reason, which is that it has the highest Correlation of the bunch. It also offers a pretty good combination of low Bias and low Error. We can get a lower error with longer window lengths, but with the trade-off of a larger Bias, as well as lower Correlation. With window lengths shorter than 9, we can get a little smaller Bias, but Error increases sharply and Correlation drops off pretty quickly too. SMA10 and SMA8 would probably be my #2 and #3 choices since they are quite similar to SMA9.

We're kind of splitting hairs here. I can't say SMA9 is absolutely the best choice, but given my statistical background and experience, it does seem like the best choice to me in a way that I can't really quantify. 


## Conclusions

Looping back to my original goal of comparing these different moving averages to the season-long average, there is no question in my mind that SMA9 is a superior predictor of Pace.^[and not only SMA9, but I would choose almost any of these moving averages of season-long] It's also important to point out that while I think SMA9 is a clear improvement over season-long, the amount of improvement overall is pretty modest. I would *not* say SMA9 is a *good* predictor of Pace, but it *is* better than season-long. Feeding SMA9 as an input into another model with additional parameters may provide an even better predictor of Pace.^[I plan to do just that myself, as well as exploring defense-adjusted Pace. I may have a Part II for this analysis that I will post at a later date.]

I will definitely revisit this analysis going forward as I'm able to add data from additional seasons to see how things change, or not, as the case may be. This will be especially important if I am building other metrics and models on top of SMA9, like I plan to.

After all of that work, the amount of improvement may not end up mattering as much as I might have initially hoped, but the experimenting it took to reach that conclusion was not only fun and interesting, but also taught me (and hopefully you!) quite a bit.

You can access and use all the code and data used in this analysis at my github [here](https://github.com/brandonsimonsen/nba-moving-averages).